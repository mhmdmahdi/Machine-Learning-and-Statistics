{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "*Explain what supervised learning is and what classification algorithms are.*\n",
    "\n",
    "In supervised learning, models are trained on a labeled dataset, where the input features are associated with corresponding target labels (classes). Essentially the model 'learns' from labelled training data to make predictions about unseen data. In the case of the iris data set the goal would be to best predict with a degree of accuracy what classification or category a new dataset would fit in to based off the current iris dataset. The training dataset consists of input features (X) and corresponding target labels (y).\n",
    "\n",
    "Classification is a type of supervised learning that involves predicting the category or class of a given input based on its features. For the iris data set these features are sepal length, sepal width, petal length and petal width. \n",
    "\n",
    "For this project, we will explore classification algorithms using the Iris Flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width   class\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load iris data set.\n",
    "df = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# Show.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target labels (y)\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "## https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cross Validation\n",
    "\n",
    "When learning the parameters of a dataset and testing it on the same dataset there can be a risk of overfitting as the learning and predicting is happening on the same dataset. To avoid this potential problem it is common to split the dataset in 'test' and 'train' data, holding out a portion of the dataset for a test. When evaluating different settings for estimators there can still be a risk of overfitting on the 'test' set because the parameters may be tweaked until the estimator performs optimally. Cross Validation is seen as a solution to this problem as it splits off another portion of the data for evaluation without reducing the number of samples used for the learning model.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "A good understanding of Cross Validation is available at the following resource.\n",
    "https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classification Algorithms\n",
    "\n",
    "Classification algorithms aim to predict the class or category of a given input. A summary prepared at The University of Toronto yielded the following results for various different classification algorithms.\n",
    "- Logistic Regression:  0.933333  (0.050000)\n",
    "- Linear Discriminant Analysis:  0.975000  (0.038188)\n",
    "- K Nearest Neigbors:  0.958333  (0.055902)\n",
    "- CART:  0.950000  (0.040825)\n",
    "- Support Vector Machine:  0.950000  (0.076376)\n",
    "- Guassian Naive Bayes:  0.966667  (0.055277)\n",
    "https://www.cs.toronto.edu/~mhsadi/code-repository/MachineLearningNotebooks/1-IrisDataset.html\n",
    "\n",
    "The study below uses 3 different classifiers and achieves an accuracy of 97%:\n",
    "- Support Vector Machine\n",
    "- Random Forest and\n",
    "- Gradient Boost\n",
    "These models were trained on the training data (80%), and their performance was evaluated using testing data (20%).\n",
    "https://www.embedded-robotics.com/iris-dataset-classification/\n",
    "\n",
    "This study for the Decision Tree Classifier yields 100% for training data, and 94.7%, for the test dataset.\n",
    "https://www.educative.io/answers/how-to-build-a-decision-tree-with-the-iris-dataset-in-python\n",
    "\n",
    "These results show that it is worth attempting a number of different classifiers ourselves to determine which is the most suitable as various different references online yielded different results, for example this paper by Abdulazeez et al. showed KNN to be the most accurate at 100% (https://www.researchgate.net/publication/351328500_Machine_Learning_Classifiers_Based_Classification_For_IRIS_Recognition).\n",
    "\n",
    "Ultimately what I've concluded from my brief research is that the classification algorithm chosen for this project would not contain much significance as the overall objective is autonomous learning and all the classifiers compared provide more than adequate results for what is considered a clean dataset with no outliers. The differences could be down to a number of different factors but as already mentioned these differences place no major significance at this point and are outside the scope of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Average Accuracy: 0.95\n",
      "KNN Average Accuracy: 0.97\n",
      "Random Forest Average Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "clf_dt = DecisionTreeClassifier(random_state=42)\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores_dt = cross_val_score(clf_dt, X, y, cv=10)\n",
    "cv_scores_knn = cross_val_score(clf_knn, X, y, cv=10)\n",
    "cv_scores_rf = cross_val_score(clf_rf, X, y, cv=10)\n",
    "\n",
    "# Print average cross-validation scores\n",
    "print(f'Decision Tree Average Accuracy: {cv_scores_dt.mean():.2f}')\n",
    "print(f'KNN Average Accuracy: {cv_scores_knn.mean():.2f}')\n",
    "print(f'Random Forest Average Accuracy: {cv_scores_rf.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision Tree Classifier\n",
    "\n",
    "I will put a further emphasis on the Decision Tree Classifier over the others. This is mainly because a Decision Tree Classifier was initially unintentionally adopted by myself through first principles with one of my first assignments as a method to classify the iris data set. The scope of the assignment was to logically think through how to classify the dataset. At this early point in my Data Analytics journey I didn't have much knowledge or background (or any for that matter) in the field of Machine Learning. My github repository which last had a commit on 08May2022 can be found at the link below \n",
    "https://github.com/mhmdmahdi/pands-project/blob/main/analysis.py\n",
    "\n",
    "In summary, I used a number of conditions to try and classify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['petal length (cm)'] <= 2.1),\n",
    "    (df['petal length (cm)'] <= 4.95) & (df['petal width (cm)'] <= 1.65),\n",
    "    (df['petal length (cm)'] >= 4.94) & (df['petal length (cm)'] <= 5.15) & (\n",
    "        df['petal width (cm)'] >= 1.55) & (df['petal width (cm)'] <= 1.71),\n",
    "    (df['petal width (cm)'] >= 1.6) & (df['petal length (cm)'] >= 5.2),\n",
    "    (df['petal width (cm)'] >= 1.52) | (df['petal length (cm)'] >= 1.51)\n",
    "]\n",
    "# Created a list of conditions with specified criteria\n",
    "\n",
    "values = [0, 1, 1, 2, 2]\n",
    "# Defined the list of values to use if the Conditions above were met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknowingly I had developed, what is essentially the foundations of a Decision Tree Classifier, and so at the conclusion of this course it would only be fitting that I use the classifier provided by sklearn as opposed to trying to build it myself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- petal_length <= 2.45\n",
      "|   |--- class: setosa\n",
      "|--- petal_length >  2.45\n",
      "|   |--- petal_length <= 4.75\n",
      "|   |   |--- petal_width <= 1.65\n",
      "|   |   |   |--- class: versicolor\n",
      "|   |   |--- petal_width >  1.65\n",
      "|   |   |   |--- class: virginica\n",
      "|   |--- petal_length >  4.75\n",
      "|   |   |--- petal_width <= 1.75\n",
      "|   |   |   |--- petal_length <= 4.95\n",
      "|   |   |   |   |--- class: versicolor\n",
      "|   |   |   |--- petal_length >  4.95\n",
      "|   |   |   |   |--- petal_width <= 1.55\n",
      "|   |   |   |   |   |--- class: virginica\n",
      "|   |   |   |   |--- petal_width >  1.55\n",
      "|   |   |   |   |   |--- petal_length <= 5.45\n",
      "|   |   |   |   |   |   |--- class: versicolor\n",
      "|   |   |   |   |   |--- petal_length >  5.45\n",
      "|   |   |   |   |   |   |--- class: virginica\n",
      "|   |   |--- petal_width >  1.75\n",
      "|   |   |   |--- petal_length <= 4.85\n",
      "|   |   |   |   |--- sepal_width <= 3.10\n",
      "|   |   |   |   |   |--- class: virginica\n",
      "|   |   |   |   |--- sepal_width >  3.10\n",
      "|   |   |   |   |   |--- class: versicolor\n",
      "|   |   |   |--- petal_length >  4.85\n",
      "|   |   |   |   |--- class: virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use export_text to generate a textual representation of the Decision Tree\n",
    "tree_rules = export_text(clf_dt, feature_names=list(X.columns))\n",
    "\n",
    "# Print the textual representation of the Decision Tree\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This representation above shows the decision rules at each node of the tree. Each decision node is associated with a feature and a threshold value, and the tree branches based on whether the condition is true or false.\n",
    "\n",
    "Known for its interpretability and ease of visualization, “Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.”\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluation Metrics and Cost Function of Decision Tree Classifier\n",
    "Evaluation metrics such as accuracy, precision, recall, and confusion matrix are used to assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation Accuracy: 0.95\n",
      "Overall Accuracy: 0.95\n",
      "Precision: 0.95\n",
      "Recall: 0.95\n",
      "\n",
      "Confusion Matrix:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  4 46]]\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "cv_predictions = cross_val_predict(clf_dt, X, y, cv=10)\n",
    "cv_scores = cross_val_score(clf_dt, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y, cv_predictions)\n",
    "precision = precision_score(y, cv_predictions, average='weighted')\n",
    "recall = recall_score(y, cv_predictions, average='weighted')\n",
    "conf_matrix = confusion_matrix(y, cv_predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Average Cross-Validation Accuracy: {cv_scores.mean():.2f}')\n",
    "print(f'Overall Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "The model's results and performance metrics are presented above:\n",
    "- An Average Cross Validation Accuracy of 0.95 (95%) indicates that the model achieved an accuracy of 95% across the 10 folds of the cross-validation. Accuracy is the ratio of correctly predicted observations to the total observations.\n",
    "- The Overall Accuracy calculated by comparing the model's predictions to the true labels across the entire dataset also shows an accuracy of 95%.\n",
    "- Precision: Precision is the number of true positives divided by the sum of true positives and false positives. It represents the accuracy of the positive predictions and shows that the model is correct 95% of the time on average.\n",
    "- Recall (Sensitivity): Recall is the number of true positives divided by the sum of true positives and false negatives. It indicates that the model is good at capturing the instances of each class as it also stands at 95%.\n",
    "\n",
    "\n",
    "The confusion matrix table shows the counts of true positive, true negative, false positive, and false negative predictions.\n",
    "In our Confusion Matrix:\n",
    "- For setosa, all 50 instances were correctly predicted (true positives), with no false positives or false negatives.\n",
    "- For versicolor, 47 instances were correctly predicted (true positives), with 3 false positives and 4 false negatives.\n",
    "- For virginica, 46 instances were correctly predicted (true positives), with 4 false positives and 3 false negatives.\n",
    "\n",
    "In summary, the model seems to perform well across various metrics, with high accuracy, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
